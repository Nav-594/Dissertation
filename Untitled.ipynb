{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4563b823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "#from sklearn.impute import SimpleImputer\n",
    "#make functions for pipeline\n",
    "def print_missing_values(data):\n",
    "    print(\"Total Missing:\")\n",
    "    for column in data.columns:\n",
    "        if data[column].isnull().any():\n",
    "            print(f\"   {column}: {data[column].isnull().sum()}\")\n",
    "            \n",
    "def balance_class(data, clusters_to_undersample, clusters_to_add):\n",
    "    undersampled_dataset = pd.DataFrame()\n",
    "\n",
    "    for cluster in clusters_to_undersample:\n",
    "        cluster_data = data[data['Info_cluster'] == cluster]\n",
    "        minority_class_len = int(cluster_data['Class'].value_counts()[-1])\n",
    "        majority_class_len = cluster_data['Class'].value_counts()[1]\n",
    "\n",
    "        majority_class_idx = cluster_data[cluster_data['Class'] == 1].index\n",
    "        minority_class_idx = cluster_data[cluster_data['Class'] == -1].index\n",
    "\n",
    "        random_majority_idx = np.random.choice(majority_class_idx, minority_class_len, replace=False)\n",
    "        undersampled_idx = np.concatenate([minority_class_idx, random_majority_idx])\n",
    "        undersampled_cluster = cluster_data.loc[undersampled_idx].copy()\n",
    "\n",
    "        undersampled_dataset = pd.concat([undersampled_dataset, undersampled_cluster])\n",
    "\n",
    "    for cluster in clusters_to_add:\n",
    "        cluster_data = data[data['Info_cluster'] == cluster]\n",
    "        undersampled_dataset = pd.concat([undersampled_dataset, cluster_data])\n",
    "\n",
    "    undersampled_dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return undersampled_dataset\n",
    "\n",
    "def data_splitting(X,Y,groups):\n",
    "    gkfold = GroupKFold(n_splits=3)\n",
    "\n",
    "    for train_idx, test_idx in gkfold.split(X, y, groups):\n",
    "        X_train, y_train= X.loc[train_idx], y.loc[train_idx]\n",
    "        X_test, y_test= X.loc[test_idx], y.loc[test_idx]\n",
    "    X2 = X_train.reset_index(drop=True)\n",
    "    y2 = y_train.reset_index(drop=True)\n",
    "    groups2 = X_train['Info_cluster']\n",
    "\n",
    "    gkfold = GroupKFold(n_splits=2)\n",
    "\n",
    "    for train_idx, test_idx in gkfold.split(X2, y2, groups2):\n",
    "        X2_train, y2_train= X2.loc[train_idx], y2.loc[train_idx]\n",
    "        X_val, y_val= X.loc[test_idx], y.loc[test_idx]\n",
    "    \n",
    "def plot_class_imbalance(split):\n",
    "    class_counts = split['Class'].value_counts()\n",
    "    n_pos = class_counts[1]\n",
    "    n_neg = class_counts[-1]\n",
    "    plt.bar(['Positive', 'Negative'], [n_pos, n_neg])\n",
    "    plt.title(f'Split {i}: Positive = {n_pos}, Negative = {n_neg}')\n",
    "    plt.show()\n",
    "    \n",
    "def data_skewness(features):\n",
    "    skewness = features.skew()\n",
    "    skewed_columns_greater = skewness[skewness > 1.5].index\n",
    "    skewed_columns_less = skewness[skewness < -1.5].index\n",
    "\n",
    "    print(\"Skewed columns with skewness greater than 1.5:\")\n",
    "    print(skewed_columns_greater)\n",
    "    print(\"Skewed columns with skewness less than -1.5:\")\n",
    "    print(skewed_columns_less)\n",
    "    \n",
    "def scale_features(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    feature_cols = list(data.columns)\n",
    "\n",
    "    # Fit the scaler to the feature data and transform it + create a new dataframe\n",
    "    data_norm = scaler.fit_transform(data[feature_cols])\n",
    "    data_norm = pd.DataFrame(data_norm, columns=feature_cols)\n",
    "\n",
    "    return data_norm\n",
    "\n",
    "def reduce_dimensionality(data, n):\n",
    "    pca = PCA(n_components=n, whiten=True)\n",
    "    datapca = pca.fit_transform(data)\n",
    "\n",
    "    data_reduced = pd.DataFrame(data=datapca, index=data.index)\n",
    "\n",
    "    return data_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46debae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the remaining preprocessing steps\n",
    "preprocessing_steps = [\n",
    "    ('missing_values', print_missing_values),\n",
    "    ('balance_class', balance_class),\n",
    "    ('data_splitting', data_splitting),\n",
    "    ('plot_class_imbalance', plot_class_imbalance),\n",
    "    ('data_skewness', data_skewness),\n",
    "    ('scaling', scale_features),\n",
    "    (('reduce_dimensionality', reduce_dimensionality)),  \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ea734c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
